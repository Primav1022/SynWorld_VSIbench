# SynWorld VSI Bench 批量处理使用说明

## 概述

为了高效处理大量数据文件夹（如100个数据文件夹），我们提供了三个处理脚本：

1. **`quick_process.py`** - 快速处理单个数据文件夹（推荐用于测试）
2. **`run_single.py`** - 处理单个数据文件夹的完整流程（包含可视化）
3. **`batch_process.py`** - 批量处理多个数据文件夹

## 数据文件夹结构

每个数据文件夹应包含以下结构：
```
data/
├── 20250820-151238/
│   ├── Screenshot_summary.csv    # 主要数据文件
│   ├── annotation/               # 标注文件
│   └── original/                 # 原始文件
├── 20250821-123456/
│   ├── Screenshot_summary.csv
│   ├── annotation/
│   └── original/
└── ...
```

## 快速处理单个文件夹

### 方法1：使用 quick_process.py（推荐用于测试）

```bash
# 处理单个文件夹
python quick_process.py 20250820-151238

# 跳过可视化脚本（更快）
python quick_process.py 20250820-151238 --skip_visualization
```

### 方法2：使用 run_single.py（完整流程）

```bash
# 处理单个文件夹（包含可视化）
python run_single.py

# 修改脚本顶部的配置来控制执行选项
# ENABLE_VISUALIZATIONS = True/False
# ENABLE_INFERENCE_SCRIPTS = True/False
# ENABLE_FRAME_EXTRACTION = True/False
```

### 输出

处理完成后，会在各个工具目录的 `output/` 文件夹中生成以下CSV文件：

- `0_data_cleanup_tool/output/ranked_unique_actor_anno.csv`
- `m_absolute_distance_tool/output/absolute_distances_all.csv`
- `m_object_size_tool/output/object_size_all.csv`
- `m_room_size_tool/output/room_size_all.csv`
- `c_object_count_tool/output/object_count_all.csv`
- `c_relative_direction_tool/output/relative_direction_all.csv`
- `c_relative_distance_tool/output/relative_distance_all.csv`
- `c_route_plan_tool/output/route_plan_all.csv`
- `s_appearance_order_tool/output/appearance_order_all.csv`

## 批量处理多个文件夹

### 使用方法

```bash
# 基本批量处理
python batch_process.py --data_root data --output_root processed_data

# 并行处理（推荐用于大量数据）
python batch_process.py --data_root data --output_root processed_data --parallel 4

# 跳过可视化脚本（更快）
python batch_process.py --data_root data --output_root processed_data --skip_visualization

# 跳过推理脚本（默认跳过）
python batch_process.py --data_root data --output_root processed_data --skip_inference
```

### 参数说明

- `--data_root`: 数据根目录（默认：`data`）
- `--output_root`: 输出根目录（默认：`processed_data`）
- `--parallel`: 并行处理数量（默认：1，推荐：CPU核心数）
- `--skip_visualization`: 跳过可视化脚本
- `--skip_inference`: 跳过推理脚本（默认：True）

### 输出结构

```
processed_data/
├── 20250820-151238/
│   ├── ranked_unique_actor_anno.csv
│   ├── absolute_distances_all.csv
│   ├── object_size_all.csv
│   ├── room_size_all.csv
│   ├── object_count_all.csv
│   ├── relative_direction_all.csv
│   ├── relative_distance_all.csv
│   ├── route_plan_all.csv
│   └── appearance_order_all.csv
├── 20250821-123456/
│   └── ...
├── processing_results.json      # 处理结果统计
└── batch_process.log           # 处理日志
```

## 处理流程

### 1. 数据清理阶段
- 清理和标准化Actor名称
- 筛选符合条件的对象（最小帧数、最小体积）
- 生成排序后的Actor信息

### 2. 测量类工具
- **绝对距离分析**: 计算对象间的最小距离
- **对象尺寸分析**: 计算对象的尺寸属性
- **房间大小分析**: 提取房间尺寸信息

### 3. 配置类工具
- **对象计数**: 根据类型和位置统计对象
- **相对方向**: 计算对象间的相对方向关系
- **相对距离**: 识别最近的对象
- **路径规划**: 生成导航路径和转向指令

### 4. 时空类工具
- **出现顺序**: 分析对象的时间出现顺序

### 5. 可视化阶段（可选）
- 生成2D/3D可视化图表
- 创建各种分析的可视化结果

## 性能优化建议

### 1. 并行处理
```bash
# 根据CPU核心数设置并行数量
python batch_process.py --parallel 8
```

### 2. 跳过可视化
```bash
# 如果不需要可视化图表，可以跳过
python batch_process.py --skip_visualization
```

### 3. 分批处理
对于100个文件夹，建议分批处理：
```bash
# 第一批：1-25
python batch_process.py --data_root data --output_root processed_batch1 --parallel 4

# 第二批：26-50
python batch_process.py --data_root data --output_root processed_batch2 --parallel 4

# 以此类推...
```

### 4. 监控处理进度
```bash
# 查看处理日志
tail -f batch_process.log

# 查看处理结果
cat processed_data/processing_results.json
```

## 错误处理

### 常见错误及解决方案

1. **脚本不存在**
   ```
   警告: 脚本不存在: xxx.py
   ```
   - 检查脚本路径是否正确
   - 确保所有工具目录都存在

2. **数据文件不存在**
   ```
   错误: 未找到Screenshot_summary.csv
   ```
   - 检查数据文件夹结构
   - 确保文件名拼写正确

3. **处理超时**
   ```
   错误: 脚本执行超时
   ```
   - 增加超时时间（修改脚本中的timeout参数）
   - 检查数据文件大小是否过大

4. **内存不足**
   - 减少并行处理数量
   - 分批处理数据

## 示例使用场景

### 场景1：快速测试单个数据
```bash
# 方法1：使用 quick_process.py（推荐）
python quick_process.py 20250820-151238 --skip_visualization

# 方法2：使用 run_single.py
python run_single.py
```

### 场景2：处理少量数据（<10个文件夹）
```bash
python batch_process.py --data_root data --output_root processed_data --parallel 2
```

### 场景3：处理大量数据（100个文件夹）
```bash
# 分批处理，每批25个
python batch_process.py --data_root data --output_root processed_batch1 --parallel 8 --skip_visualization
```

### 场景4：生成完整数据集（包含可视化）
```bash
python batch_process.py --data_root data --output_root processed_full --parallel 4
```

## 注意事项

1. **磁盘空间**: 确保有足够的磁盘空间存储输出文件
2. **内存使用**: 并行处理会增加内存使用，根据系统配置调整
3. **网络存储**: 如果数据在网络存储上，建议先复制到本地处理
4. **备份**: 处理前建议备份原始数据
5. **日志**: 处理日志会保存在 `batch_process.log` 中，可用于问题排查

## 故障排除

如果遇到问题，请检查：

1. Python环境和依赖包是否正确安装
2. 数据文件夹结构是否符合要求
3. 脚本文件是否存在且可执行
4. 系统资源（CPU、内存、磁盘）是否充足
5. 查看详细的错误日志

## 联系支持

如果遇到无法解决的问题，请提供：
- 错误日志内容
- 数据文件夹结构
- 系统环境信息
- 使用的命令参数
